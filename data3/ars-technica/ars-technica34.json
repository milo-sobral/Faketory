{"id": "How to make elections secure in the age of digital operatives", "paragraph": "Front page layoutSite themeSign up or login to join the discussions!\nAnnalee Newitz\n    -  Oct 24, 2018 1:10 pm UTC\nIn our latest episode of Ars Technica Live, we talk about election security. My guest was Alex Stamos, a researcher at Stanford who just happened to be the CSO at Facebook when the company discovered Russian operatives meddling in the US presidential election. He told us about that experience and what's worrying him about the future of US democracy.It was odd for technical experts like Stamos and his team at Facebook to find themselves at ground zero of a political propaganda war. Stamos explained that infosec researchers are not typically trained to deal with things like weaponized memes. \"We had ignored that the vast majority of human harm caused online has no interesting technical component,\" he said wryly. \"It's a technically correct use of the products we build.\"Stamos and his team discovered Russian-controlled propaganda accounts almost by accident while investigating political extremist activity. They were on the lookout for governments dropping malware and doing account takeovers, and one team focused on Russian misuse of the platform. They were not prepared to find thousands of puppet accounts controlled by Russian operatives sharing memes and fake news.There were two distinct Russian influence campaigns leading up to the 2016 presidential election. One, headed by Russian intelligence agency GRU, was aimed specifically at undermining Hillary Clinton's campaign. It was, as Stamos put it, a \"hack and leak campaign.\" The GRU focused on infiltrating the DNC headquarters, then engineered a careful leak campaign to smear the Democratic party.Though the GRU used typical infosec techniques to break into DNC networks, the breathtakingly effective \"leak\" part of their campaign was not technical at all. It was sheer media manipulation. \"They know that something that seems like a secret or leak gets more play than something that\u2019s open,\" Stamos explained. \"The fact that they had secret stolen information allowed them to leak it to people in the press and push the narratives they wanted. There were 1,100 news stories in the first 30 days of the GRU campaign.\"And it worked. People started talking about how the election was rigged. Animosity grew between Bernie Democrats and Hillary Democrats.Stamos confessed that his experience at Facebook taught him that it's \"extremely difficult\" to stop a GRU-style attack. Security engineers can defend against many technical hacks. But they can't stop a toxic news cycle. \"That is a vulnerability difficult to protect in a country where we have a free and unlicensed media,\" Stamos said.The other Russian operation, known as the IRA campaign, was entirely devoted to social media propaganda. IRA stands for \"internet research agency,\" but in reality it refers to a loosely linked set of troll farms and private organizations. Their relationship with the Russian state remains unclear, but Stamos said we do know their operations stretch back years before the 2016 GRU meddling. Their goal, as far as his team could tell, was to \"get people in the US to hate each other and think everybody online is a Russian troll.\"A typical IRA campaign would involve setting up Facebook activist pages on either side of a hot-button issue like race, immigration, or gun rights. Then the two pages would develop followings and get into \"fights\" designed to incite violence between people in real life. Some of the fake accounts organized real-life pro-Trump rallies\u00a0and tried to incite counter-protests with their anti-Trump accounts.To combat these IRA attacks, Facebook used its \"real identity\" policy. The company couldn't weed out these fake accounts with anti-bot algorithms because they weren't actually bots. They were cyborgs. \"They're humans with technological support to create and age accounts so that they look legit before weaponizing those accounts and using them to push propaganda,\u201d Stamos said.When the security team found suspicious accounts, they would challenge users to show some kind of real-world ID to verify their legitimacy. That worked in many cases but not all. \"Of course professionals can create fake IDs,\" Stamos admitted. \"So it's problematic.\" But, he added, it's better than trying to decide what's legitimate speech and deleting accounts on that basis.Based on what he learned at Facebook and in his new job as a Stanford researcher, Stamos thinks the threat of election meddling isn't going away. He's been studying election security in other countries and noted that the next big event to watch from a disinformation perspective will be the 2019 Indian election.Another election of interest was the recent general election in Mexico. Researchers found that online disinformation was mostly bankrolled by groups associated with domestic political parties in that country. \"That's something we need to think about in the US,\" Stamos said. \"There's no reason why the Koch brothers couldn't create their own IRA. It's not clear that it would even be illegal.\"Stamos said his biggest worry is that the Russian playbook is out there for anyone to use. Especially if the US doesn't punish Russia for election meddling, other nations and groups won't see any downside. \"Why not go for it?\" he joked. \"We could end up with US elections becoming the World Cup of information warfare. Everybody wants to play.\"I asked what we might expect during upcoming US elections, and Stamos said we have to start by asking what the Russians really want. He doesn't think they're interested in casting bogus votes for a pro-Russia candidate. They just want to prove to the world that US democracy is weak. To accomplish that goal, the GRU and IRA will do what they can to \"insert uncertainty into who won an election for as long as possible.\"\"It's hard to throw an entire election,\" Stamos mused. \"But it's not difficult to mess up voting rolls or take down the Secretary of State's website.\"The point is that it doesn't take much to cast doubt on an election's credibility. Indeed, Russian hackers could leave behind a lot of clues that they'd broken into a local election authority, partly to inspire a long FBI investigation. No matter what the outcome of that investigation is, a large percentage of the US electorate would start questioning whether their politicians are legitimate. If adversaries manage to meddle in two or three elections in a row, it could seriously undermine people's faith in democracy.Stamos warned that other nations will be following in Russia's footsteps, watching closely, learning what works and what doesn't.Addressing election security concerns means taking a hard look at what exactly social media platforms are and what they do. Stamos said the best way to think about platforms is by dividing them up into three products that exist in a stack. The bottom of the stack is the place where users exist, chatting with each other and sharing information. The next level of the stack, he said, is \"discovery and recommendation engines.\" These are tools like the Facebook timeline or YouTube's recommendation system. Finally, at the top of the stack, there's advertising.\"The further you go up the stack, the more powerful the tools are,\" Stamos explained. \"From my perspective, the higher you get, the less free-speech concerns you have.\"As a result, he believes regulation should start at the top. \"We spend a lot of time on the bottom, worrying about who should be kicked off platforms completely, and, in my opinion, that's a dangerous place to play,\" he said. \"You're silencing people, versus taking away their ability to use incredibly powerful tools.\"Advertising tools allow people to do extremely narrow targeting, which Stamos views as anti-democratic. Micro-targeting allows campaigns or PACs to divide the electorate up into very tiny segments and deliver extremely tailored messages to them. These messages often contradict messages the same campaign sends to another highly targeted segment.Unlike many of his compatriots in Silicon Valley, Stamos believes that the solutions to this problem won't come from tech companies\u2014they'll come from the government.Stamos suggested that the Honest Ads Act, or a similar piece of legislation, could mandate a minimum segment size for advertising. That way, voters are getting internally consistent messages from campaigns. Plus, it would mean regulation for all online ad companies and not just the big names like Google and Facebook. \"You need regulation for everybody, not just two or three companies,\" he said.The US government also needs to \"get competent about defensive cybersecurity,\" Stamos asserted. Right now, the US is focused exclusively on offense, which leads to weapons like Stuxnet. That's great, but we also need security experts to patch servers.Stamos imagines an agency that has no law enforcement responsibility, whose goal is to guarantee digital security on a national level. France and Germany already have agencies that work with all political campaigns to guarantee campaign security. It's his hope that one day the US will have a cyber-defense agency like those. It would offer infosec experts an incentive to discover software vulnerabilities before the bad guys do. With a defensive cybersecurity agency, the American government would have a chance to stop the next GRU campaign before it starts.After our conversation, Stamos fielded several excellent questions from the audience. You can watch the video to hear our whole discussion.Ars Technica Live is filmed on the first Wednesday of the month before a live audience at Eli's Mile High Club in Oakland, California. If you liked this episode, why not check out the whole series?Listing image by Elijah Nouvelage/Bloomberg via Getty ImagesYou must login or create an account to comment.Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox.\n  CNMN Collection\n  WIRED Media Group\n  \u00a9 2018 Cond\u00e9 Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 5/25/18) and Privacy Policy and Cookie Statement (updated 5/25/18) and Ars Technica Addendum (effective 8/21/2018). Ars may earn compensation on sales from links on this site. Read our affiliate link policy.\nYour California Privacy Rights\n  The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond\u00e9 Nast.\nAd Choices\n"}