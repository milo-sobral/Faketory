{"id": "It\u2019s only a matter of time until terrorists use AI as a weapon", "paragraph": "\n                            TNW uses cookies to personalize content and ads to\n                            make our site easier for you to use.\n                            We do also share that information with third parties for\n                            advertising & analytics.\n                        \n            by Tristan Greene\n            \u2014 \n                        in Artificial Intelligence\nDo you have a family emergency plan for autonomous weapon attacks? Stop, drop, and roll isn\u2019t going to fool the drone tracking you. Duck and cover? Does it even matter?It\u2019s hard to separate the hyperbole and science fiction-nonsense from practical concerns \u2014 for regular people \u2014 when it comes to autonomous weapons. Despite the late Stephen Hawking\u2019s warnings, we\u2019re probably decades away from the dystopian nightmare military\u00a0experts predict\u00a0the battlefield will become.It\u2019s all about cryptocurrency and blockchainAnd, it\u2019s not like there\u2019s a crime-syndicate of extremely well-financed super villains developing warehouses full of laser-equipped murder bots. It\u2019s easy for the average individual to frame the killer robot problem as something that might be important in the future, but not-so-pressing right now.Yet there\u2019s always some important technology figure warning us about some unknown doom \u2014 typically in vague and spooky ways. Do these warnings even matter to the average Joe or Jane?This is nothing. In a few years, that bot will move so fast you\u2019ll need a strobe light to see it. Sweet dreams\u2026 https://t.co/0MYNixQXMw\u2014 Elon Musk (@elonmusk) November 26, 2017Probably not. There\u2019s this sort of pallor of existential dread that comes along with knowing the Pentagon and the Kremlin are hellbent on finding ways to exploit AI for warfare, but for the most part we don\u2019t have time to worry about autonomous missiles and Project JEDI.Killer robots don\u2019t loom as menacingly in our fear-centers as more familiar threats, so we tell ourselves that, as long as we don\u2019t end up in some warzone, we\u2019re probably safe.We live in civilized places with access to indoor plumbing and emergency response services. This gives us the confidence to point at Alexa and Google Assistant and say \u201cis that the best you got?\u201d\u00a0Then we laugh off the idea that the robots are going to rise up \u2014 forgetting it\u2019s the ingenuity of evil people we should fear, not the robustness of a neural network\u2019s code.It seems shocking that, as of October 2018, we\u2019ve yet to see the headline that\u2019s going to send the killer robots\u00a0debate into high gear: \u201cOfficials still searching for humans behind terrorist attack carried out by autonomous weapons.\u201d But, sadly, it\u2019s almost surely coming.The Human Rights Watch\u00a0understands this. Through its\u00a0Campaign To Stop Killer Robots\u00a0the organization has dedicated itself to the incredibly difficult mission of spreading awareness about autonomous weapons \u2014 mostly as it pertains to government, military, and police use.And, if you ask us, the problem of autonomous weapons is one the general public might not even be capable of fully understanding yet, so the Watch has its work cut out. Ice skate uphill much?In a video posted today, the Campaign shows us a dramatic fictional slice-of-life that paints machines as unpredictable and dangerous:The Campaign\u2019s coordinator, Mary Wareham, told TNW:The video shows what a future attack by fully autonomous weapons might look like. It also shows the serious concerns about the likely lack of accountability for fully autonomous weapons systems, as Human Rights Watch has documented.These videos often come off as fear-mongering and far-fetched. But consider this: as best as we can tell, there\u2019s no technology in this fictional video that isn\u2019t already here in reality. This is a future that could have happened yesterday, technologically speaking.Particularly worrisome, in light of Wareham\u2019s comment about accountability, is the notion that weapons developed by governments for military use often end up in the hands of terrorist organizations.Long-time readers might remember the \u201cSlaughterbots\u201d video by Stop Autonomous Weapons we reported on last year. In it, a big tech company takes to the conference stage to show off the latest and greatest gadget for military use. Horror ensues.Much like the \u201cHated in the Nation\u201d episode of \u201cBlack Mirror,\u201d it shows us how robots could kill us in ways the average person might not have considered. These may be fiction, but they\u2019re important for helping those of us who don\u2019t think like engineers visualize how autonomous weapons could affect our lives.But you don\u2019t have to turn to fiction to find examples of the ways AI could be used to automate mass murder. Earlier this month Syrian engineer Hamzah Salam built a fully-functioning autonomous weapons platform with an AK-47 and a computer. He calls it an \u201celectronic sniper.\u201dIt\u2019s literally a \u201csentry gun,\u201d like the ones from video games such as \u201cCall of Duty\u201d and \u201cBorderlands.\u201d And it exists right now.According to Sputnik News Salam says the platform:\u2026 can use any small-arms weapon, from a machine gun to a sniper rifle. Cameras transmit a signal to a computer, which analyzes the data received. Its main task is to track movement. The computer has several preset scenarios. If it notices odd behavior in a given quadrant, it will open fire.We live in a world where you can 3D print a firearm, mount it to a battery-powered tripod, and use open-source machine learning software and a Raspberry Pi (that may be an exaggeration, maybe not) to create something that, just a few years ago, would have seemed like experimental weapons at the cutting-edge of military research.Things are changing faster than the public perception can handle.Should you be worried about some other country\u2019s killer machines occupying Main Street, USA? Probably not today.But we\u2019re in the last few innocent moments before the first AI-powered massacre happens somewhere. And the scariest part is that there\u2019s likely nothing we can do about it if we remain ignorant to the scope of the immediate\u00a0threat.You can learn more about the fight against autonomous weapons by visiting the Campaign To Stop Killer Robots.And don\u2019t forget to check out TNW\u2019s artificial intelligence section for continuing\u00a0news and analysis on the world of machines that learn.\nRead next:\n\n        OnePlus pushes its 6T launch event up to avoid Apple overlap    \nStay tuned with our weekly recap of what\u2019s hot & cool by our CEO Boris.\n        Join over 260,000 subscribers!\n    \n                Sit back and let the hottest tech news come to you by the magic of electronic mail.\n            \n                Prefer to get the news as it happens? Follow us on social media.\n            \n1.76M followers\n                        \n1M likes\n                        \n                Got two minutes to spare? We'd love to know a bit more about our readers.\nStart!\n\n                All data collected in the survey is anonymous.\n            "}